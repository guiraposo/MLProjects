{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPI1cy5AjHHFIbMneDrkEvS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guiraposo/MLProjects/blob/main/Stock_Trend_RNN/rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DVUmE0zKnPgK"
      },
      "outputs": [],
      "source": [
        "#Import the relevant libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import the training set and test set\n",
        "data_train = pd.read_csv('/content/Google_Stock_Price_Train.csv')\n",
        "training_set = data_train.iloc[:,1:2].values # Get the values in np array form."
      ],
      "metadata": {
        "id": "09G1W1gcoWCl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature scaling\n",
        "#For RNNs it is recommended to use normalization for feature scaling\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range = (0, 1))\n",
        "training_set_scaled = sc.fit_transform(training_set) #Fit and transform the training set\n"
      ],
      "metadata": {
        "id": "9F-OjSh2ouxK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the a data structure with 60 timesteps (3 months).\n",
        "# Initialization as an empty loop\n",
        "X_train = []\n",
        "y_train = []\n",
        "for day in range(60, 1258):\n",
        "  X_train.append(training_set_scaled[day-60:day, 0]) # Stocks on the 60 previous days\n",
        "  y_train.append(training_set_scaled[day, 0]) # Stock value on the day + 1\n",
        "X_train, y_train = np.array(X_train), np.array(y_train) # Convert to numpy arrays"
      ],
      "metadata": {
        "id": "OuefkCvyqIEO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshaping the data. New dimension for predictors\n",
        "# Will not be implemented here\n",
        "\n",
        "X_train = np.reshape(X_train, (X_train.shape[0],X_train.shape[1], 1))"
      ],
      "metadata": {
        "id": "h6uvOO7bro3W"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the RNN\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout"
      ],
      "metadata": {
        "id": "DlS36ZbZs9fK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the neural network architecture\n",
        "\n",
        "#Initializating the RNN\n",
        "regressor = Sequential()\n",
        "\n",
        "# First LSTM layer and dropout regularization\n",
        "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
        "regressor.add(Dropout(0.2)) # Check\n",
        "\n",
        "# Second LSTM layer + Regularization\n",
        "regressor.add(LSTM(units = 50, return_sequences = True))\n",
        "regressor.add(Dropout(0.2)) # Check\n",
        "# Third LSTM layer + Regularization\n",
        "regressor.add(LSTM(units = 50, return_sequences = True))\n",
        "regressor.add(Dropout(0.2)) # Check\n",
        "\n",
        "# Fourth LSTM layer + Regularization\n",
        "regressor.add(LSTM(units = 50, return_sequences = False)) #Last layer so no return\n",
        "regressor.add(Dropout(0.2)) # Check\n",
        "\n",
        "#Add output layer\n",
        "regressor.add(Dense(units = 1))\n",
        "\n"
      ],
      "metadata": {
        "id": "iSgvgdidtO3c"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compling the NN\n",
        "\n",
        "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n"
      ],
      "metadata": {
        "id": "2eIkrSYFtUfB"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KaoKPHbNv8XG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}